{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57a73989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "'''maximum numbers in input'''\n",
    "DIGITS = 3\n",
    "'''Input may optionally be reversed'''\n",
    "REVERSE = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9537313d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total questions: 50000\n"
     ]
    }
   ],
   "source": [
    "class CharacterTable:\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one-hot integer representation\n",
    "    + Decode the one-hot or integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One-hot encode given string C.\n",
    "        # Arguments\n",
    "            C: string, to be encoded.\n",
    "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        \"\"\"Decode the given vector or 2D array to their character output.\n",
    "        # Arguments\n",
    "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
    "                or a vector of character indices (used with `calc_argmax=False`).\n",
    "            calc_argmax: Whether to find the character index with maximum\n",
    "                probability, defaults to `True`.\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return \"\".join(self.indices_char[x] for x in x)\n",
    "\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = \"0123456789+ \"\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print(\"Generating data...\")\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(\n",
    "        \"\".join(\n",
    "            np.random.choice(list(\"0123456789\"))\n",
    "            for i in range(np.random.randint(1, DIGITS + 1))\n",
    "        )\n",
    "    )\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = \"{}+{}\".format(a, b)\n",
    "    query = q + \" \" * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += \" \" * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print(\"Total questions:\", len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b0ea42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zaid's Laptop\\AppData\\Local\\Temp\\ipykernel_25792\\1046822725.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
      "C:\\Users\\Zaid's Laptop\\AppData\\Local\\Temp\\ipykernel_25792\\1046822725.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "'''# To normalize, split, and map strings to integers we need to add a vectorization layer for strings'''\n",
    "print(\"Vectorization...\")\n",
    "'''Create empty matrix that contains zeros'''\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print(\"Training Data:\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"Validation Data:\")\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31c536c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               72192     \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 4, 128)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 4, 128)            131584    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4, 12)             1548      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Build model...\")\n",
    "num_layers = 1  # Try to add more LSTM layers!\n",
    "'''We will import the sequential model from keras library '''\n",
    "'''it based on Sequence to sequence learning'''\n",
    "'''In dense layer we used softmax activation function, in the output layer we choosed adam. as evaluating metric we will choose\n",
    "accuracy'''\n",
    "model = keras.Sequential()\n",
    "# \"Encode\" the input sequence using a LSTM, producing an output of size 128.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(layers.LSTM(128, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last output of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(num_layers):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(layers.LSTM(128, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4554ec49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1\n",
      "1407/1407 [==============================] - 34s 20ms/step - loss: 1.7530 - accuracy: 0.3584 - val_loss: 1.5607 - val_accuracy: 0.4104\n",
      "1/1 [==============================] - 1s 733ms/step\n",
      "Q 976+3   T 979  ☒ 903 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 663+51  T 714  ☒ 611 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 829+351 T 1180 ☒ 1113\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 930+37  T 967  ☒ 901 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 66+722  T 788  ☒ 717 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 64+678  T 742  ☒ 713 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 610+217 T 827  ☒ 811 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 423+54  T 477  ☒ 515 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 88+154  T 242  ☒ 551 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 10+632  T 642  ☒ 271 \n",
      "\n",
      "Iteration 2\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 1.3680 - accuracy: 0.4863 - val_loss: 1.1979 - val_accuracy: 0.5507\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 29+799  T 828  ☒ 991 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 540+74  T 614  ☒ 616 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 231+241 T 472  ☒ 496 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 565+80  T 645  ☒ 641 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 514+54  T 568  ☒ 569 \n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Q 254+22  T 276  ☒ 271 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 433+486 T 919  ☒ 901 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 562+7   T 569  ☒ 561 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 339+32  T 371  ☒ 361 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 151+80  T 231  ☒ 211 \n",
      "\n",
      "Iteration 3\n",
      "1407/1407 [==============================] - 34s 24ms/step - loss: 1.0772 - accuracy: 0.5976 - val_loss: 0.9872 - val_accuracy: 0.6335\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Q 587+3   T 590  ☒ 582 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 155+391 T 546  ☒ 599 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 6+666   T 672  ☒ 669 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 709+818 T 1527 ☒ 1597\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 354+870 T 1224 ☒ 1292\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Q 439+25  T 464  ☒ 463 \n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Q 77+426  T 503  ☒ 402 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 46+721  T 767  ☒ 762 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 297+13  T 310  ☒ 309 \n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Q 122+568 T 690  ☒ 618 \n",
      "\n",
      "Iteration 4\n",
      "1407/1407 [==============================] - 31s 22ms/step - loss: 0.9124 - accuracy: 0.6611 - val_loss: 0.8453 - val_accuracy: 0.6900\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 902+39  T 941  ☒ 943 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 842+418 T 1260 ☒ 1263\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 80+144  T 224  ☒ 227 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 434+93  T 527  ☒ 523 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 419+31  T 450  ☒ 458 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 25+427  T 452  ☒ 456 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 14+906  T 920  ☒ 926 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 7+244   T 251  ☒ 256 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 65+533  T 598  ☒ 590 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 427+946 T 1373 ☒ 1363\n",
      "\n",
      "Iteration 5\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 0.7978 - accuracy: 0.7056 - val_loss: 0.7793 - val_accuracy: 0.7107\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 467+17  T 484  ☒ 480 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 65+304  T 369  ☒ 363 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 313+9   T 322  ☒ 310 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 80+96   T 176  ☒ 173 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 90+828  T 918  ☒ 913 \n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Q 41+346  T 387  ☑ 387 \n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Q 8+397   T 405  ☒ 403 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 60+820  T 880  ☒ 883 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 2+741   T 743  ☒ 742 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 12+506  T 518  ☑ 518 \n",
      "\n",
      "Iteration 6\n",
      "1407/1407 [==============================] - 31s 22ms/step - loss: 0.7125 - accuracy: 0.7391 - val_loss: 0.6846 - val_accuracy: 0.7451\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 261+679 T 940  ☒ 936 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 114+654 T 768  ☒ 776 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 41+500  T 541  ☑ 541 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 314+66  T 380  ☒ 389 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 9+985   T 994  ☒ 992 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 82+575  T 657  ☒ 656 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 314+533 T 847  ☒ 841 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 654+891 T 1545 ☒ 1546\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 2+260   T 262  ☒ 261 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 441+34  T 475  ☒ 477 \n",
      "\n",
      "Iteration 7\n",
      "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6055 - accuracy: 0.7785 - val_loss: 0.5070 - val_accuracy: 0.8180\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 80+158  T 238  ☒ 237 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 50+842  T 892  ☑ 892 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 63+81   T 144  ☒ 145 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 46+5    T 51   ☑ 51  \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 111+52  T 163  ☑ 163 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 891+477 T 1368 ☒ 1360\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Q 81+567  T 648  ☑ 648 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 702+2   T 704  ☑ 704 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 309+230 T 539  ☑ 539 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 461+79  T 540  ☒ 530 \n",
      "\n",
      "Iteration 8\n",
      "1407/1407 [==============================] - 29s 21ms/step - loss: 0.3568 - accuracy: 0.8784 - val_loss: 0.2473 - val_accuracy: 0.9269\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 847+73  T 920  ☑ 920 \n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Q 640+319 T 959  ☑ 959 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 464+429 T 893  ☑ 893 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 428+529 T 957  ☑ 957 \n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Q 897+549 T 1446 ☑ 1446\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 635+597 T 1232 ☑ 1232\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 825+5   T 830  ☑ 830 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 345+9   T 354  ☑ 354 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 731+880 T 1611 ☒ 1612\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 76+59   T 135  ☑ 135 \n",
      "\n",
      "Iteration 9\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 0.1969 - accuracy: 0.9468 - val_loss: 0.1826 - val_accuracy: 0.9520\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 61+75   T 136  ☑ 136 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 967+7   T 974  ☑ 974 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 48+315  T 363  ☑ 363 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 65+518  T 583  ☑ 583 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 5+14    T 19   ☒ 10  \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 580+615 T 1195 ☑ 1195\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 784+203 T 987  ☑ 987 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 379+8   T 387  ☑ 387 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 4+800   T 804  ☒ 803 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 73+42   T 115  ☑ 115 \n",
      "\n",
      "Iteration 10\n",
      "1407/1407 [==============================] - 31s 22ms/step - loss: 0.1182 - accuracy: 0.9722 - val_loss: 0.0957 - val_accuracy: 0.9757\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 500+29  T 529  ☑ 529 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 44+563  T 607  ☑ 607 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 948+88  T 1036 ☑ 1036\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 310+32  T 342  ☑ 342 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 670+53  T 723  ☑ 723 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 58+51   T 109  ☒ 119 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 49+997  T 1046 ☒ 1056\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 10+224  T 234  ☑ 234 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 952+43  T 995  ☑ 995 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 162+488 T 650  ☑ 650 \n",
      "\n",
      "Iteration 11\n",
      "1407/1407 [==============================] - 31s 22ms/step - loss: 0.0861 - accuracy: 0.9790 - val_loss: 0.0720 - val_accuracy: 0.9833\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 390+865 T 1255 ☑ 1255\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 81+172  T 253  ☑ 253 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 94+698  T 792  ☑ 792 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 6+669   T 675  ☑ 675 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 394+3   T 397  ☑ 397 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 115+5   T 120  ☑ 120 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 304+24  T 328  ☑ 328 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 937+90  T 1027 ☑ 1027\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 249+6   T 255  ☑ 255 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 53+692  T 745  ☑ 745 \n",
      "\n",
      "Iteration 12\n",
      "1407/1407 [==============================] - 26s 18ms/step - loss: 0.0762 - accuracy: 0.9791 - val_loss: 0.0791 - val_accuracy: 0.9784\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 727+3   T 730  ☑ 730 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 16+43   T 59   ☑ 59  \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 253+4   T 257  ☑ 257 \n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 30+452  T 482  ☑ 482 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 88+523  T 611  ☑ 611 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 158+468 T 626  ☑ 626 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 94+781  T 875  ☑ 875 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 151+218 T 369  ☑ 369 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 12+860  T 872  ☑ 872 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 9+51    T 60   ☑ 60  \n",
      "\n",
      "Iteration 13\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.0467 - accuracy: 0.9897 - val_loss: 0.0312 - val_accuracy: 0.9944\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Q 732+237 T 969  ☑ 969 \n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Q 939+68  T 1007 ☑ 1007\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Q 356+533 T 889  ☑ 889 \n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Q 740+967 T 1707 ☑ 1707\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Q 47+447  T 494  ☑ 494 \n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Q 51+973  T 1024 ☑ 1024\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Q 85+262  T 347  ☑ 347 \n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Q 675+583 T 1258 ☑ 1258\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 693+681 T 1374 ☑ 1374\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Q 537+213 T 750  ☑ 750 \n",
      "\n",
      "Iteration 14\n",
      "1407/1407 [==============================] - 25s 18ms/step - loss: 0.0510 - accuracy: 0.9867 - val_loss: 0.0259 - val_accuracy: 0.9954\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 18+558  T 576  ☑ 576 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 6+136   T 142  ☑ 142 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 341+381 T 722  ☑ 722 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 493+51  T 544  ☑ 544 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 731+941 T 1672 ☑ 1672\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 419+31  T 450  ☑ 450 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 23+296  T 319  ☑ 319 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 6+753   T 759  ☑ 759 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 9+385   T 394  ☑ 394 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 453+77  T 530  ☑ 530 \n",
      "\n",
      "Iteration 15\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 0.0388 - accuracy: 0.9902 - val_loss: 0.0991 - val_accuracy: 0.9669\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Q 46+427  T 473  ☑ 473 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 647+72  T 719  ☑ 719 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 996+492 T 1488 ☑ 1488\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 198+68  T 266  ☒ 267 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 84+883  T 967  ☑ 967 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 52+421  T 473  ☑ 473 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 685+60  T 745  ☑ 745 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 945+98  T 1043 ☑ 1043\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 498+29  T 527  ☑ 527 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 730+115 T 845  ☒ 745 \n",
      "\n",
      "Iteration 16\n",
      "1407/1407 [==============================] - 29s 21ms/step - loss: 0.0283 - accuracy: 0.9930 - val_loss: 0.0464 - val_accuracy: 0.9851\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 987+22  T 1009 ☑ 1009\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 681+317 T 998  ☑ 998 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 194+45  T 239  ☑ 239 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 22+230  T 252  ☑ 252 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 675+583 T 1258 ☑ 1258\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 976+41  T 1017 ☑ 1017\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 464+61  T 525  ☑ 525 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 91+200  T 291  ☑ 291 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 67+549  T 616  ☑ 616 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 807+52  T 859  ☑ 859 \n",
      "\n",
      "Iteration 17\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0312 - accuracy: 0.9917 - val_loss: 0.0308 - val_accuracy: 0.9915\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 286+991 T 1277 ☑ 1277\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 285+888 T 1173 ☑ 1173\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 708+33  T 741  ☑ 741 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 70+65   T 135  ☑ 135 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 53+718  T 771  ☒ 781 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 5+275   T 280  ☑ 280 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 48+313  T 361  ☒ 371 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 38+346  T 384  ☑ 384 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 6+136   T 142  ☑ 142 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 64+72   T 136  ☑ 136 \n",
      "\n",
      "Iteration 18\n",
      "1407/1407 [==============================] - 32s 23ms/step - loss: 0.0259 - accuracy: 0.9933 - val_loss: 0.0151 - val_accuracy: 0.9966\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 19+138  T 157  ☑ 157 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 4+7     T 11   ☑ 11  \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 2+803   T 805  ☑ 805 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 87+258  T 345  ☑ 345 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 302+9   T 311  ☑ 311 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 952+666 T 1618 ☑ 1618\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 73+29   T 102  ☑ 102 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 662+773 T 1435 ☑ 1435\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 504+9   T 513  ☑ 513 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 94+698  T 792  ☑ 792 \n",
      "\n",
      "Iteration 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 27s 19ms/step - loss: 0.0291 - accuracy: 0.9924 - val_loss: 0.0094 - val_accuracy: 0.9980\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 73+148  T 221  ☑ 221 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 122+49  T 171  ☑ 171 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 94+476  T 570  ☑ 570 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 79+408  T 487  ☑ 487 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 64+693  T 757  ☑ 757 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 857+69  T 926  ☑ 926 \n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 876+24  T 900  ☑ 900 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 677+41  T 718  ☑ 718 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 66+469  T 535  ☑ 535 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 47+745  T 792  ☑ 792 \n",
      "\n",
      "Iteration 20\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0311 - accuracy: 0.9916 - val_loss: 0.0090 - val_accuracy: 0.9986\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 91+362  T 453  ☑ 453 \n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Q 8+673   T 681  ☑ 681 \n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Q 89+101  T 190  ☑ 190 \n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Q 66+469  T 535  ☑ 535 \n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Q 926+868 T 1794 ☑ 1794\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 491+644 T 1135 ☑ 1135\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 79+666  T 745  ☑ 745 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 72+60   T 132  ☑ 132 \n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Q 902+39  T 941  ☑ 941 \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Q 27+613  T 640  ☑ 640 \n",
      "\n",
      "Iteration 21\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.0251 - accuracy: 0.9931 - val_loss: 0.0178 - val_accuracy: 0.9953\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 31+826  T 857  ☑ 857 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 615+91  T 706  ☑ 706 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 24+331  T 355  ☑ 355 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 297+56  T 353  ☑ 353 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 67+549  T 616  ☑ 616 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 779+20  T 799  ☑ 799 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 61+41   T 102  ☑ 102 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 602+262 T 864  ☑ 864 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 96+604  T 700  ☑ 700 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 445+517 T 962  ☑ 962 \n",
      "\n",
      "Iteration 22\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.0179 - accuracy: 0.9954 - val_loss: 0.0068 - val_accuracy: 0.9988\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 9+720   T 729  ☑ 729 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 456+5   T 461  ☑ 461 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 92+157  T 249  ☑ 249 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 255+886 T 1141 ☑ 1141\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 249+6   T 255  ☑ 255 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 168+54  T 222  ☑ 222 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 916+9   T 925  ☑ 925 \n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Q 433+64  T 497  ☑ 497 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 46+732  T 778  ☑ 778 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 94+161  T 255  ☑ 255 \n",
      "\n",
      "Iteration 23\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0254 - accuracy: 0.9929 - val_loss: 0.0066 - val_accuracy: 0.9990\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 847+73  T 920  ☑ 920 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 89+69   T 158  ☑ 158 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 294+322 T 616  ☑ 616 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 534+54  T 588  ☑ 588 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 285+888 T 1173 ☑ 1173\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 532+595 T 1127 ☑ 1127\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 354+565 T 919  ☑ 919 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 74+86   T 160  ☑ 160 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 76+339  T 415  ☑ 415 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 40+83   T 123  ☑ 123 \n",
      "\n",
      "Iteration 24\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.0216 - accuracy: 0.9940 - val_loss: 0.0140 - val_accuracy: 0.9962\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 688+592 T 1280 ☑ 1280\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 768+908 T 1676 ☑ 1676\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 524+705 T 1229 ☑ 1229\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 436+154 T 590  ☑ 590 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 56+878  T 934  ☑ 934 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 683+267 T 950  ☑ 950 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 86+53   T 139  ☑ 139 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 254+22  T 276  ☑ 276 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 46+40   T 86   ☑ 86  \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 186+133 T 319  ☑ 319 \n",
      "\n",
      "Iteration 25\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0133 - accuracy: 0.9967 - val_loss: 0.0063 - val_accuracy: 0.9988\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 81+343  T 424  ☑ 424 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 430+73  T 503  ☑ 503 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 274+859 T 1133 ☑ 1133\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 32+2    T 34   ☑ 34  \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 758+39  T 797  ☑ 797 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 499+3   T 502  ☑ 502 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 504+807 T 1311 ☑ 1311\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 272+370 T 642  ☑ 642 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 57+344  T 401  ☑ 401 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 55+299  T 354  ☑ 354 \n",
      "\n",
      "Iteration 26\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.0283 - accuracy: 0.9927 - val_loss: 0.0053 - val_accuracy: 0.9993\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 71+4    T 75   ☑ 75  \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 25+979  T 1004 ☑ 1004\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Q 433+64  T 497  ☑ 497 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 18+80   T 98   ☑ 98  \n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Q 863+47  T 910  ☑ 910 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 265+41  T 306  ☑ 306 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 13+458  T 471  ☑ 471 \n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Q 27+342  T 369  ☑ 369 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 66+345  T 411  ☑ 411 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 284+84  T 368  ☑ 368 \n",
      "\n",
      "Iteration 27\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.0274 - accuracy: 0.9923 - val_loss: 0.0204 - val_accuracy: 0.9941\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 717+789 T 1506 ☑ 1506\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 91+908  T 999  ☑ 999 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 520+20  T 540  ☑ 540 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 3+433   T 436  ☑ 436 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 32+235  T 267  ☑ 267 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 50+709  T 759  ☑ 759 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 991+630 T 1621 ☑ 1621\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 60+607  T 667  ☑ 667 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 463+91  T 554  ☑ 554 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 374+1   T 375  ☑ 375 \n",
      "\n",
      "Iteration 28\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.0169 - accuracy: 0.9956 - val_loss: 0.0371 - val_accuracy: 0.9871\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 775+310 T 1085 ☑ 1085\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Q 83+719  T 802  ☑ 802 \n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Q 475+73  T 548  ☑ 548 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 67+818  T 885  ☑ 885 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 192+23  T 215  ☑ 215 \n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Q 893+22  T 915  ☑ 915 \n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Q 76+848  T 924  ☑ 924 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 234+771 T 1005 ☑ 1005\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Q 48+864  T 912  ☑ 912 \n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Q 258+880 T 1138 ☑ 1138\n",
      "\n",
      "Iteration 29\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.0072 - val_accuracy: 0.9981\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 42+592  T 634  ☑ 634 \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Q 861+54  T 915  ☑ 915 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 336+74  T 410  ☑ 410 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 69+34   T 103  ☑ 103 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 908+97  T 1005 ☑ 1005\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 4+660   T 664  ☑ 664 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 5+275   T 280  ☑ 280 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 94+425  T 519  ☑ 519 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 578+38  T 616  ☑ 616 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 76+848  T 924  ☑ 924 \n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 32\n",
    "'''In this step we will fit the model using the train and test datasets.'''\n",
    "\n",
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for epoch in range(1, epochs):\n",
    "    print()\n",
    "    print(\"Iteration\", epoch)\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=1,\n",
    "        validation_data=(x_val, y_val),\n",
    "    )\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
    "        print(\"T\", correct, end=\" \")\n",
    "        if correct == guess:\n",
    "            print(\"☑ \" + guess)\n",
    "        else:\n",
    "            print(\"☒ \" + guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a934ed",
   "metadata": {},
   "source": [
    "In this example we have build a sequence to sequence model that capable to learn to add two numbers, provided as strings. We encode the input strings to one-hot integer representation, then we train our model and adjust weights and bias to get the prefered predictions. then we decode the integer representation to their character output.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
